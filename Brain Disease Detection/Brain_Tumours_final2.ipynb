{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSO4KiZ3rjph"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsUFOE5_rsQ8",
        "outputId": "3d7f1a43-e6d2-4b5b-99d0-4b3871c12742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            " 91% 135M/149M [00:01<00:00, 102MB/s]\n",
            "100% 149M/149M [00:01<00:00, 110MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAGAzuTfrsUK"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/brain-tumor-mri-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMylvgRXrsXG"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten,BatchNormalization,Dropout,Conv2D,MaxPooling2D\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications import ConvNeXtLarge\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0aklD-6rsaw",
        "outputId": "17ee2d22-36f8-4592-bb25-a9b1ba63e8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5712 images belonging to 4 classes.\n",
            "Found 1311 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/Training',\n",
        "        target_size=(299, 299),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/Testing',\n",
        "        target_size=(299, 299),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVKPmvo0KkwI"
      },
      "outputs": [],
      "source": [
        "base_model = Xception(input_shape=(299,299,3), weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnNEkC4sJPka",
        "outputId": "1251c8b0-6d86-472d-92df-9ea54003aa32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_layer_4 False\n",
            "block1_conv1 False\n",
            "block1_conv1_bn False\n",
            "block1_conv1_act False\n",
            "block1_conv2 False\n",
            "block1_conv2_bn False\n",
            "block1_conv2_act False\n",
            "block2_sepconv1 False\n",
            "block2_sepconv1_bn False\n",
            "block2_sepconv2_act False\n",
            "block2_sepconv2 False\n",
            "block2_sepconv2_bn False\n",
            "conv2d_16 False\n",
            "block2_pool False\n",
            "batch_normalization_16 False\n",
            "add_48 False\n",
            "block3_sepconv1_act False\n",
            "block3_sepconv1 False\n",
            "block3_sepconv1_bn False\n",
            "block3_sepconv2_act False\n",
            "block3_sepconv2 False\n",
            "block3_sepconv2_bn False\n",
            "conv2d_17 False\n",
            "block3_pool False\n",
            "batch_normalization_17 False\n",
            "add_49 False\n",
            "block4_sepconv1_act False\n",
            "block4_sepconv1 False\n",
            "block4_sepconv1_bn False\n",
            "block4_sepconv2_act False\n",
            "block4_sepconv2 False\n",
            "block4_sepconv2_bn False\n",
            "conv2d_18 False\n",
            "block4_pool False\n",
            "batch_normalization_18 False\n",
            "add_50 False\n",
            "block5_sepconv1_act False\n",
            "block5_sepconv1 False\n",
            "block5_sepconv1_bn False\n",
            "block5_sepconv2_act False\n",
            "block5_sepconv2 False\n",
            "block5_sepconv2_bn False\n",
            "block5_sepconv3_act False\n",
            "block5_sepconv3 False\n",
            "block5_sepconv3_bn False\n",
            "add_51 False\n",
            "block6_sepconv1_act False\n",
            "block6_sepconv1 False\n",
            "block6_sepconv1_bn False\n",
            "block6_sepconv2_act False\n",
            "block6_sepconv2 False\n",
            "block6_sepconv2_bn False\n",
            "block6_sepconv3_act False\n",
            "block6_sepconv3 False\n",
            "block6_sepconv3_bn False\n",
            "add_52 False\n",
            "block7_sepconv1_act False\n",
            "block7_sepconv1 False\n",
            "block7_sepconv1_bn False\n",
            "block7_sepconv2_act False\n",
            "block7_sepconv2 False\n",
            "block7_sepconv2_bn False\n",
            "block7_sepconv3_act False\n",
            "block7_sepconv3 False\n",
            "block7_sepconv3_bn False\n",
            "add_53 False\n",
            "block8_sepconv1_act False\n",
            "block8_sepconv1 False\n",
            "block8_sepconv1_bn False\n",
            "block8_sepconv2_act False\n",
            "block8_sepconv2 False\n",
            "block8_sepconv2_bn False\n",
            "block8_sepconv3_act False\n",
            "block8_sepconv3 False\n",
            "block8_sepconv3_bn False\n",
            "add_54 False\n",
            "block9_sepconv1_act False\n",
            "block9_sepconv1 False\n",
            "block9_sepconv1_bn False\n",
            "block9_sepconv2_act False\n",
            "block9_sepconv2 False\n",
            "block9_sepconv2_bn False\n",
            "block9_sepconv3_act False\n",
            "block9_sepconv3 False\n",
            "block9_sepconv3_bn False\n",
            "add_55 False\n",
            "block10_sepconv1_act False\n",
            "block10_sepconv1 False\n",
            "block10_sepconv1_bn False\n",
            "block10_sepconv2_act False\n",
            "block10_sepconv2 False\n",
            "block10_sepconv2_bn False\n",
            "block10_sepconv3_act False\n",
            "block10_sepconv3 False\n",
            "block10_sepconv3_bn False\n",
            "add_56 False\n",
            "block11_sepconv1_act False\n",
            "block11_sepconv1 True\n",
            "block11_sepconv1_bn True\n",
            "block11_sepconv2_act True\n",
            "block11_sepconv2 True\n",
            "block11_sepconv2_bn True\n",
            "block11_sepconv3_act True\n",
            "block11_sepconv3 True\n",
            "block11_sepconv3_bn True\n",
            "add_57 True\n",
            "block12_sepconv1_act True\n",
            "block12_sepconv1 True\n",
            "block12_sepconv1_bn True\n",
            "block12_sepconv2_act True\n",
            "block12_sepconv2 True\n",
            "block12_sepconv2_bn True\n",
            "block12_sepconv3_act True\n",
            "block12_sepconv3 True\n",
            "block12_sepconv3_bn True\n",
            "add_58 True\n",
            "block13_sepconv1_act True\n",
            "block13_sepconv1 True\n",
            "block13_sepconv1_bn True\n",
            "block13_sepconv2_act True\n",
            "block13_sepconv2 True\n",
            "block13_sepconv2_bn True\n",
            "conv2d_19 True\n",
            "block13_pool True\n",
            "batch_normalization_19 True\n",
            "add_59 True\n",
            "block14_sepconv1 True\n",
            "block14_sepconv1_bn True\n",
            "block14_sepconv1_act True\n",
            "block14_sepconv2 True\n",
            "block14_sepconv2_bn True\n",
            "block14_sepconv2_act True\n"
          ]
        }
      ],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Flag to control when to start fine-tuning\n",
        "set_trainable = False\n",
        "\n",
        "# Unfreeze layers from a specific layer onwards\n",
        "for layer in base_model.layers:\n",
        "    if layer.name == 'block11_sepconv1':  # Replace with the layer name from where you want to start fine-tuning\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Print the trainable status of each layer\n",
        "for layer in base_model.layers:\n",
        "    print(layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si7ei01ftWyb"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(124,activation='relu'))\n",
        "model.add(Dense(124,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(4,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sQaQmrItxQa"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIxuqzHJ20C5",
        "outputId": "01504e66-3184-4e48-864e-6748f32eb4f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 802ms/step - accuracy: 0.9892 - loss: 0.0430 - val_accuracy: 0.9779 - val_loss: 0.1595\n",
            "Epoch 2/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 800ms/step - accuracy: 0.9793 - loss: 0.0910 - val_accuracy: 0.9619 - val_loss: 0.1490\n",
            "Epoch 3/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 809ms/step - accuracy: 0.9898 - loss: 0.0348 - val_accuracy: 0.9931 - val_loss: 0.0366\n",
            "Epoch 4/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 803ms/step - accuracy: 0.9918 - loss: 0.0258 - val_accuracy: 0.9771 - val_loss: 0.1681\n",
            "Epoch 5/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 806ms/step - accuracy: 0.9926 - loss: 0.0315 - val_accuracy: 0.9794 - val_loss: 0.0756\n",
            "Epoch 6/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 802ms/step - accuracy: 0.9923 - loss: 0.0333 - val_accuracy: 0.9886 - val_loss: 0.0609\n",
            "Epoch 7/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 797ms/step - accuracy: 0.9928 - loss: 0.0216 - val_accuracy: 0.9855 - val_loss: 0.0492\n",
            "Epoch 8/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 800ms/step - accuracy: 0.9923 - loss: 0.0277 - val_accuracy: 0.9840 - val_loss: 0.0500\n",
            "Epoch 9/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 802ms/step - accuracy: 0.9963 - loss: 0.0096 - val_accuracy: 0.9832 - val_loss: 0.0962\n",
            "Epoch 10/10\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 798ms/step - accuracy: 0.9967 - loss: 0.0162 - val_accuracy: 0.9954 - val_loss: 0.0219\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Sfjb-H1ffT",
        "outputId": "49fd5594-9d97-4c8b-ac91-2ca1327034df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.save('brain_tumor_final2.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TinFRbdCfd8Z",
        "outputId": "3d0b5d75-fe38-41ca-cd79-e497e2522c20"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_bf8fa2b6-6dc1-40a6-a953-32a7a2a608cc\", \"brain_tumor_final2.h5\", 468972432)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "from google.colab import files\n",
        "files.download('brain_tumor_final2.h5')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
